{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiliaze Spark and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear stale Spark context references\n",
    "pyspark.SparkContext._gateway = None\n",
    "pyspark.SparkContext._jvm = None\n",
    "pyspark.SparkContext._active_spark_context = None\n",
    "\n",
    "# Ensure local IP is set correctly to avoid network conflicts\n",
    "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\"\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLensALS\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.6\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", True) \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.default.parallelism\", \"8\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load movies and ratings data from S3\n",
    "movies_df = spark.read.csv(\"data/movies.csv\", header=True, inferSchema=True)\n",
    "ratings_df = spark.read.csv(\"data/ratings.csv\", header=True, inferSchema=True)\n",
    "\n",
    "ratings_df.printSchema()\n",
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+----+----+------+\n",
      "|user|item|rating|\n",
      "+----+----+------+\n",
      "|   1|  17|   4.0|\n",
      "|   1|  25|   1.0|\n",
      "|   1|  29|   2.0|\n",
      "|   1|  30|   5.0|\n",
      "|   1|  32|   5.0|\n",
      "+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Training data count: 25572748\n",
      "Testing data count: 6394124\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns and rename them for ALS\n",
    "matrix = ratings_df.selectExpr(\"userId as user\", \"movieId as item\", \"rating\")\n",
    "\n",
    "# Check schema and sample data\n",
    "matrix.printSchema()\n",
    "matrix.show(5)\n",
    "\n",
    "# Split the data into training and test sets (80%-20%)\n",
    "(training, test) = matrix.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Training data count:\", training.count())\n",
    "print(\"Testing data count:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Tracking Setup with MLFlow and Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        als = ALS(userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\", coldStartStrategy=\"drop\", nonnegative=True,\n",
    "                  rank=int(params['rank']),\n",
    "                  maxIter=int(params['maxIter']),\n",
    "                  regParam=params['regParam'])\n",
    "\n",
    "        model = als.fit(training)\n",
    "        predictions = model.transform(test)\n",
    "\n",
    "        evaluator_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "        evaluator_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "        \n",
    "        rmse = evaluator_rmse.evaluate(predictions)\n",
    "        mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "        mlflow.log_param(\"rank\", params['rank'])\n",
    "        mlflow.log_param(\"maxIter\", params['maxIter'])\n",
    "        mlflow.log_param(\"regParam\", params['regParam'])\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameter Search Space\n",
    "search_space = {\n",
    "    'rank': hp.choice('rank', [10, 20, 30, 50]),\n",
    "    'maxIter': hp.quniform('maxIter', 5, 15, 5),\n",
    "    'regParam': hp.loguniform('regParam', np.log(0.001), np.log(1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [46:42<00:00, 140.12s/trial, best loss: 0.7710100154492384]\n",
      "Best Parameters: {'maxIter': np.float64(15.0), 'rank': np.int64(3), 'regParam': np.float64(0.05392921721979053)}\n"
     ]
    }
   ],
   "source": [
    "# Execute Hyperparameter Optimization\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=objective,\n",
    "                   space=search_space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=20,\n",
    "                   trials=trials)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model with the best params (lowest MAE tracked using MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final selected hyperparameters (based on MAE optimization)\n",
    "final_params = {\n",
    "    'maxIter': 15,\n",
    "    'rank': 30,\n",
    "    'regParam': 0.0287\n",
    "}\n",
    "\n",
    "# Train final ALS model with selected hyperparameters\n",
    "final_als = ALS(userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\",\n",
    "                coldStartStrategy=\"drop\", nonnegative=True,\n",
    "                rank=final_params['rank'],\n",
    "                maxIter=final_params['maxIter'],\n",
    "                regParam=final_params['regParam'])\n",
    "\n",
    "final_model = final_als.fit(training)\n",
    "\n",
    "# Save ALS model as Parquet\n",
    "final_model.save(\"models/best_als_model\")\n",
    "\n",
    "print(\"✅ Best ALS model saved with Rank={final_params['rank']}, MaxIter={final_params['maxIter']}, RegParam={final_params['regParam']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Actual vs Predicted Ratings for a random user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Ratings for User 46404:\n",
      "+-----------------------------------------------------+------+\n",
      "|title                                                |rating|\n",
      "+-----------------------------------------------------+------+\n",
      "|Braveheart (1995)                                    |4.0   |\n",
      "|Star Wars: Episode V - The Empire Strikes Back (1980)|3.5   |\n",
      "|Big Lebowski, The (1998)                             |3.5   |\n",
      "|Fight Club (1999)                                    |3.0   |\n",
      "|Departed, The (2006)                                 |3.0   |\n",
      "|Bourne Ultimatum, The (2007)                         |3.0   |\n",
      "+-----------------------------------------------------+------+\n",
      "\n",
      "Predicted Ratings for User 46404 (Top 10 Unseen Movies):\n",
      "+-------------------------------------------------+------------------+\n",
      "|title                                            |prediction        |\n",
      "+-------------------------------------------------+------------------+\n",
      "|Africa addio (1966)                              |5.0               |\n",
      "|Histoire(s) du Cinéma: All the (Hi)stories (1988)|4.167826426387353 |\n",
      "|Finisterre (2003)                                |3.0998412595146703|\n",
      "|Histoire(s) du Cinéma: A New Wave (1998)         |2.9866313187170643|\n",
      "|Crazy Stone (Fengkuang de shitou) (2006)         |2.677963697872617 |\n",
      "|Queen: Days of Our Lives (2011)                  |2.1574087567497235|\n",
      "|Doggiewoggiez! Poochiewoochiez! (2012)           |2.0737850497690458|\n",
      "|Sankarabharanam (1979)                           |1.351419556307332 |\n",
      "|Lamb (2016)                                      |1.3007956541539263|\n",
      "|Sharpe's Eagle (1993)                            |0.5               |\n",
      "+-------------------------------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best ALS model\n",
    "final_model = ALSModel.load(\"models/best_als_model\")\n",
    "\n",
    "# Perform predictions on the test set\n",
    "predictions = final_model.transform(test)\n",
    "\n",
    "from pyspark.sql.functions import col, expr, explode, min, max\n",
    "\n",
    "# Select a random user from the test set\n",
    "random_user = test.select(\"user\").distinct().orderBy(expr(\"rand()\")).limit(1).collect()[0][\"user\"]\n",
    "\n",
    "# Get actual ratings for this user\n",
    "actual_ratings = test.filter(col(\"user\") == random_user).join(movies_df, test.item == movies_df.movieId).select(\"title\", \"rating\")\n",
    "\n",
    "# Generate recommendations for the selected user\n",
    "top_n_recommendations = final_model.recommendForAllUsers(10)\n",
    "user_recommendations = top_n_recommendations.filter(col(\"user\") == random_user)\n",
    "\n",
    "# Explode recommendations into separate rows\n",
    "user_recommendations = user_recommendations.select(\"user\", explode(\"recommendations\").alias(\"recommendation\"))\n",
    "\n",
    "# Extract movie ID and predicted rating\n",
    "user_recommendations = user_recommendations.select(col(\"user\"), col(\"recommendation.item\").alias(\"movieId\"), col(\"recommendation.rating\").alias(\"prediction\"))\n",
    "\n",
    "# Compute min and max predictions\n",
    "min_pred = user_recommendations.agg(min(\"prediction\")).collect()[0][0]\n",
    "max_pred = user_recommendations.agg(max(\"prediction\")).collect()[0][0]\n",
    "\n",
    "# Apply Min-Max Scaling: Scale values into [0.5, 5.0] range\n",
    "user_recommendations = user_recommendations.withColumn(\n",
    "    \"prediction\",\n",
    "    ((col(\"prediction\") - min_pred) / (max_pred - min_pred)) * (5.0 - 0.5) + 0.5\n",
    ")\n",
    "\n",
    "# Join with movie titles\n",
    "predicted_ratings = user_recommendations.join(movies_df, user_recommendations.movieId == movies_df.movieId) \\\n",
    "    .select(\"title\", \"prediction\") \\\n",
    "    .orderBy(col(\"prediction\").desc())\n",
    "\n",
    "# Show results\n",
    "print(f\"Actual Ratings for User {random_user}:\")\n",
    "actual_ratings.show(truncate=False)\n",
    "\n",
    "print(f\"Predicted Ratings for User {random_user} (Top 10 Unseen Movies):\")\n",
    "predicted_ratings.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
